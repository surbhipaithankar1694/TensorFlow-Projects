{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some California Census Data, we'll be trying to use various features of an individual to predict what class of income they belong in (>50k or <=50k). \n",
    "\n",
    "Here is some information about the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column Name</th>\n",
    "<th>Type</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>age</td>\n",
    "<td>Continuous</td>\n",
    "<td>The age of the individual</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>workclass</td>\n",
    "<td>Categorical</td>\n",
    "<td>The type of employer the  individual has (government,  military, private, etc.).</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fnlwgt</td>\n",
    "<td>Continuous</td>\n",
    "<td>The number of people the census  takers believe that observation  represents (sample weight). This  variable will not be used.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education</td>\n",
    "<td>Categorical</td>\n",
    "<td>The highest level of education  achieved for that individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education_num</td>\n",
    "<td>Continuous</td>\n",
    "<td>The highest level of education in  numerical form.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>marital_status</td>\n",
    "<td>Categorical</td>\n",
    "<td>Marital status of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>occupation</td>\n",
    "<td>Categorical</td>\n",
    "<td>The occupation of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>relationship</td>\n",
    "<td>Categorical</td>\n",
    "<td>Wife, Own-child, Husband,  Not-in-family, Other-relative,  Unmarried.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>race</td>\n",
    "<td>Categorical</td>\n",
    "<td>White, Asian-Pac-Islander,  Amer-Indian-Eskimo, Other, Black.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>gender</td>\n",
    "<td>Categorical</td>\n",
    "<td>Female, Male.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_gain</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital gains recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_loss</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital Losses recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>hours_per_week</td>\n",
    "<td>Continuous</td>\n",
    "<td>Hours worked per week.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>native_country</td>\n",
    "<td>Categorical</td>\n",
    "<td>Country of origin of the  individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>income</td>\n",
    "<td>Categorical</td>\n",
    "<td>\"&gt;50K\" or \"&lt;=50K\", meaning  whether the person makes more  than \\$50,000 annually.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the census_data.csv data with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census_data = pd.read_csv('census_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TensorFlow won't be able to understand strings as labels, you'll need to use pandas .apply() method to apply a custom function that converts them to 0s and 1s. **\n",
    "\n",
    "** Convert the Label column to 0s and 1s instead of strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertor(income):\n",
    "    if income == ' <=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data['income_bracket'] = census_data['income_bracket'].apply(convertor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country  income_bracket  \n",
       "0             0              40   United-States               0  \n",
       "1             0              13   United-States               0  \n",
       "2             0              40   United-States               0  \n",
       "3             0              40   United-States               0  \n",
       "4             0              40            Cuba               0  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = census_data.drop('income_bracket',axis=1)\n",
    "y = census_data['income_bracket']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Feature Columns for tf.esitmator\n",
    "\n",
    "** Take note of categorical vs continuous values! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
       "       'capital_loss', 'hours_per_week', 'native_country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20895</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3384</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>46</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18919</th>\n",
       "      <td>46</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31685</th>\n",
       "      <td>60</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age   workclass      education  education_num       marital_status  \\\n",
       "20895   22     Private        HS-grad              9        Never-married   \n",
       "3384    47     Private        HS-grad              9   Married-civ-spouse   \n",
       "1832    46   Local-gov   Some-college             10   Married-civ-spouse   \n",
       "18919   46   State-gov   Some-college             10             Divorced   \n",
       "31685   60     Private        HS-grad              9   Married-civ-spouse   \n",
       "\n",
       "               occupation relationship    race   gender  capital_gain  \\\n",
       "20895        Adm-clerical    Own-child   White   Female             0   \n",
       "3384    Machine-op-inspct         Wife   Black   Female         15024   \n",
       "1832       Prof-specialty      Husband   White     Male             0   \n",
       "18919        Adm-clerical    Unmarried   White   Female             0   \n",
       "31685        Adm-clerical      Husband   White     Male             0   \n",
       "\n",
       "       capital_loss  hours_per_week  native_country  \n",
       "20895             0              28   United-States  \n",
       "3384              0              40   United-States  \n",
       "1832              0              24   United-States  \n",
       "18919             0              48   United-States  \n",
       "31685             0              40   United-States  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workclass = tf.feature_column.categorical_column_with_hash_bucket('workclass',10)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket('education',20)\n",
    "marital_status =  tf.feature_column.categorical_column_with_hash_bucket('marital_status',7)\n",
    "occupation =  tf.feature_column.categorical_column_with_hash_bucket('occupation',20)\n",
    "relationship =  tf.feature_column.categorical_column_with_hash_bucket('relationship',10)\n",
    "race =  tf.feature_column.categorical_column_with_hash_bucket('race',5)\n",
    "gender =  tf.feature_column.categorical_column_with_hash_bucket('gender',2)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket('native_country',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "workclass = tf.feature_column.embedding_column(workclass,dimension = 10)\n",
    "education = tf.feature_column.embedding_column(education,dimension = 20)\n",
    "marital_status = tf.feature_column.embedding_column(marital_status,dimension = 7)\n",
    "occupation = tf.feature_column.embedding_column(occupation,dimension = 20)\n",
    "relationship = tf.feature_column.embedding_column(relationship,dimension = 10)\n",
    "race = tf.feature_column.embedding_column(race,dimension = 5)\n",
    "gender = tf.feature_column.embedding_column(gender,dimension = 2)\n",
    "native_country = tf.feature_column.embedding_column(native_country,dimension = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "age = tf.feature_column.numeric_column('age')\n",
    "education_num = tf.feature_column.numeric_column('education_num')\n",
    "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "hours_per_week = tf.feature_column.numeric_column('hours_per_week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [age, workclass, education, education_num, marital_status,\n",
    "       occupation, relationship, race, gender, capital_gain,\n",
    "       capital_loss, hours_per_week, native_country]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function\n",
    "\n",
    "** Batch_size is up to you. We set shuffle equal to true!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_function = tf.estimator.inputs.pandas_input_fn(X_train,y_train,batch_size = 10,num_epochs = 1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your model with tf.estimator\n",
    "\n",
    "**Create a DNNClassifier, for this we need to create embedded columns out of the cateogrical feature that use strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Surbhi\\AppData\\Local\\Temp\\tmp0stj2tkz\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Surbhi\\\\AppData\\\\Local\\\\Temp\\\\tmp0stj2tkz', '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': 1, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_save_checkpoints_steps': None}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNClassifier([20,20,20],feat_cols,n_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Surbhi\\AppData\\Local\\Temp\\tmp0stj2tkz\\model.ckpt.\n",
      "INFO:tensorflow:loss = 34.7322, step = 1\n",
      "INFO:tensorflow:global_step/sec: 181.955\n",
      "INFO:tensorflow:loss = 1.35862, step = 101 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.685\n",
      "INFO:tensorflow:loss = 3.51996, step = 201 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.483\n",
      "INFO:tensorflow:loss = 5.70743, step = 301 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.877\n",
      "INFO:tensorflow:loss = 3.61647, step = 401 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.332\n",
      "INFO:tensorflow:loss = 2.49765, step = 501 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.303\n",
      "INFO:tensorflow:loss = 3.96214, step = 601 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.533\n",
      "INFO:tensorflow:loss = 3.34283, step = 701 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.244\n",
      "INFO:tensorflow:loss = 1.3932, step = 801 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.224\n",
      "INFO:tensorflow:loss = 5.31633, step = 901 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.714\n",
      "INFO:tensorflow:loss = 1.02211, step = 1001 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.303\n",
      "INFO:tensorflow:loss = 6.07818, step = 1101 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.57\n",
      "INFO:tensorflow:loss = 22.2821, step = 1201 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.224\n",
      "INFO:tensorflow:loss = 3.76369, step = 1301 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.402\n",
      "INFO:tensorflow:loss = 1.71481, step = 1401 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.717\n",
      "INFO:tensorflow:loss = 4.4029, step = 1501 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.794\n",
      "INFO:tensorflow:loss = 4.8991, step = 1601 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.792\n",
      "INFO:tensorflow:loss = 2.3598, step = 1701 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.116\n",
      "INFO:tensorflow:loss = 1.61221, step = 1801 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.823\n",
      "INFO:tensorflow:loss = 3.42001, step = 1901 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.621\n",
      "INFO:tensorflow:loss = 5.54661, step = 2001 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.476\n",
      "INFO:tensorflow:loss = 2.40296, step = 2101 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.548\n",
      "INFO:tensorflow:loss = 1.73887, step = 2201 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.141\n",
      "INFO:tensorflow:loss = 4.74625, step = 2301 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.466\n",
      "INFO:tensorflow:loss = 2.55839, step = 2401 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.663\n",
      "INFO:tensorflow:loss = 4.5675, step = 2501 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.148\n",
      "INFO:tensorflow:loss = 2.91104, step = 2601 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.244\n",
      "INFO:tensorflow:loss = 4.41709, step = 2701 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.369\n",
      "INFO:tensorflow:loss = 0.626879, step = 2801 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.01\n",
      "INFO:tensorflow:loss = 5.54977, step = 2901 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.243\n",
      "INFO:tensorflow:loss = 3.8321, step = 3001 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.407\n",
      "INFO:tensorflow:loss = 7.90895, step = 3101 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.99\n",
      "INFO:tensorflow:loss = 3.51298, step = 3201 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.311\n",
      "INFO:tensorflow:loss = 2.12699, step = 3301 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.83\n",
      "INFO:tensorflow:loss = 4.5954, step = 3401 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.392\n",
      "INFO:tensorflow:loss = 2.69853, step = 3501 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.636\n",
      "INFO:tensorflow:loss = 4.50572, step = 3601 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.989\n",
      "INFO:tensorflow:loss = 1.77305, step = 3701 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.654\n",
      "INFO:tensorflow:loss = 1.87436, step = 3801 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.284\n",
      "INFO:tensorflow:loss = 2.91028, step = 3901 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.482\n",
      "INFO:tensorflow:loss = 4.06251, step = 4001 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.034\n",
      "INFO:tensorflow:loss = 4.01887, step = 4101 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.793\n",
      "INFO:tensorflow:loss = 2.55738, step = 4201 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.913\n",
      "INFO:tensorflow:loss = 3.79273, step = 4301 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.937\n",
      "INFO:tensorflow:loss = 3.84153, step = 4401 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.047\n",
      "INFO:tensorflow:loss = 2.89698, step = 4501 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.328\n",
      "INFO:tensorflow:loss = 5.98061, step = 4601 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.418\n",
      "INFO:tensorflow:loss = 1.89764, step = 4701 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.234\n",
      "INFO:tensorflow:loss = 3.26051, step = 4801 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.323\n",
      "INFO:tensorflow:loss = 1.73443, step = 4901 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.995\n",
      "INFO:tensorflow:loss = 3.26722, step = 5001 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.501\n",
      "INFO:tensorflow:loss = 3.78723, step = 5101 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.053\n",
      "INFO:tensorflow:loss = 0.738122, step = 5201 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.67\n",
      "INFO:tensorflow:loss = 5.92389, step = 5301 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.294\n",
      "INFO:tensorflow:loss = 2.68794, step = 5401 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.435\n",
      "INFO:tensorflow:loss = 2.28365, step = 5501 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.282\n",
      "INFO:tensorflow:loss = 1.24704, step = 5601 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.781\n",
      "INFO:tensorflow:loss = 4.53526, step = 5701 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.42\n",
      "INFO:tensorflow:loss = 3.65859, step = 5801 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.613\n",
      "INFO:tensorflow:loss = 5.388, step = 5901 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.196\n",
      "INFO:tensorflow:loss = 3.48944, step = 6001 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.945\n",
      "INFO:tensorflow:loss = 4.0548, step = 6101 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.965\n",
      "INFO:tensorflow:loss = 2.4213, step = 6201 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.736\n",
      "INFO:tensorflow:loss = 3.28932, step = 6301 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.207\n",
      "INFO:tensorflow:loss = 5.12496, step = 6401 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.341\n",
      "INFO:tensorflow:loss = 3.65462, step = 6501 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.049\n",
      "INFO:tensorflow:loss = 0.754801, step = 6601 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.616\n",
      "INFO:tensorflow:loss = 2.79047, step = 6701 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.972\n",
      "INFO:tensorflow:loss = 8.19678, step = 6801 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.035\n",
      "INFO:tensorflow:loss = 3.71881, step = 6901 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.582\n",
      "INFO:tensorflow:loss = 2.32796, step = 7001 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.235\n",
      "INFO:tensorflow:loss = 7.67613, step = 7101 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.269\n",
      "INFO:tensorflow:loss = 6.03557, step = 7201 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.581\n",
      "INFO:tensorflow:loss = 2.95925, step = 7301 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.784\n",
      "INFO:tensorflow:loss = 0.470968, step = 7401 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.391\n",
      "INFO:tensorflow:loss = 2.29877, step = 7501 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.851\n",
      "INFO:tensorflow:loss = 3.39843, step = 7601 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.226\n",
      "INFO:tensorflow:loss = 4.19419, step = 7701 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.166\n",
      "INFO:tensorflow:loss = 3.60847, step = 7801 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.882\n",
      "INFO:tensorflow:loss = 1.03195, step = 7901 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.526\n",
      "INFO:tensorflow:loss = 3.74997, step = 8001 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.255\n",
      "INFO:tensorflow:loss = 4.83028, step = 8101 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.623\n",
      "INFO:tensorflow:loss = 8.84297, step = 8201 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.562\n",
      "INFO:tensorflow:loss = 1.24563, step = 8301 (0.384 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 282.045\n",
      "INFO:tensorflow:loss = 1.78724, step = 8401 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.722\n",
      "INFO:tensorflow:loss = 2.45861, step = 8501 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.677\n",
      "INFO:tensorflow:loss = 2.57327, step = 8601 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.663\n",
      "INFO:tensorflow:loss = 3.97022, step = 8701 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.881\n",
      "INFO:tensorflow:loss = 2.0077, step = 8801 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.108\n",
      "INFO:tensorflow:loss = 3.53512, step = 8901 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.908\n",
      "INFO:tensorflow:loss = 2.38481, step = 9001 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.585\n",
      "INFO:tensorflow:loss = 4.19483, step = 9101 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.919\n",
      "INFO:tensorflow:loss = 1.82461, step = 9201 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.252\n",
      "INFO:tensorflow:loss = 2.88831, step = 9301 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.933\n",
      "INFO:tensorflow:loss = 2.36265, step = 9401 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.644\n",
      "INFO:tensorflow:loss = 3.7996, step = 9501 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.697\n",
      "INFO:tensorflow:loss = 1.04865, step = 9601 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.917\n",
      "INFO:tensorflow:loss = 2.93749, step = 9701 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.872\n",
      "INFO:tensorflow:loss = 2.44896, step = 9801 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.391\n",
      "INFO:tensorflow:loss = 0.976455, step = 9901 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.24\n",
      "INFO:tensorflow:loss = 2.73013, step = 10001 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.092\n",
      "INFO:tensorflow:loss = 0.834783, step = 10101 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.319\n",
      "INFO:tensorflow:loss = 1.04328, step = 10201 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.806\n",
      "INFO:tensorflow:loss = 3.84793, step = 10301 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.375\n",
      "INFO:tensorflow:loss = 1.97852, step = 10401 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.055\n",
      "INFO:tensorflow:loss = 3.46989, step = 10501 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.817\n",
      "INFO:tensorflow:loss = 3.13512, step = 10601 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.217\n",
      "INFO:tensorflow:loss = 3.28209, step = 10701 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.815\n",
      "INFO:tensorflow:loss = 2.57137, step = 10801 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.018\n",
      "INFO:tensorflow:loss = 0.295713, step = 10901 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.457\n",
      "INFO:tensorflow:loss = 3.64443, step = 11001 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.274\n",
      "INFO:tensorflow:loss = 1.16955, step = 11101 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.735\n",
      "INFO:tensorflow:loss = 3.0456, step = 11201 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.759\n",
      "INFO:tensorflow:loss = 1.50582, step = 11301 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.151\n",
      "INFO:tensorflow:loss = 5.71207, step = 11401 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.224\n",
      "INFO:tensorflow:loss = 4.19787, step = 11501 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.139\n",
      "INFO:tensorflow:loss = 5.58235, step = 11601 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.956\n",
      "INFO:tensorflow:loss = 4.96495, step = 11701 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.771\n",
      "INFO:tensorflow:loss = 3.17289, step = 11801 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.259\n",
      "INFO:tensorflow:loss = 1.16061, step = 11901 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.041\n",
      "INFO:tensorflow:loss = 4.53473, step = 12001 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.648\n",
      "INFO:tensorflow:loss = 1.40068, step = 12101 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.068\n",
      "INFO:tensorflow:loss = 1.07024, step = 12201 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.32\n",
      "INFO:tensorflow:loss = 2.33236, step = 12301 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.877\n",
      "INFO:tensorflow:loss = 2.30642, step = 12401 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.972\n",
      "INFO:tensorflow:loss = 4.45701, step = 12501 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.528\n",
      "INFO:tensorflow:loss = 2.25977, step = 12601 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.208\n",
      "INFO:tensorflow:loss = 4.1795, step = 12701 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.5\n",
      "INFO:tensorflow:loss = 2.3854, step = 12801 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.613\n",
      "INFO:tensorflow:loss = 4.11335, step = 12901 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.632\n",
      "INFO:tensorflow:loss = 12.0583, step = 13001 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.409\n",
      "INFO:tensorflow:loss = 3.04204, step = 13101 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.616\n",
      "INFO:tensorflow:loss = 3.7273, step = 13201 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.29\n",
      "INFO:tensorflow:loss = 2.44439, step = 13301 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.094\n",
      "INFO:tensorflow:loss = 1.9953, step = 13401 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.602\n",
      "INFO:tensorflow:loss = 3.11814, step = 13501 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.327\n",
      "INFO:tensorflow:loss = 1.74008, step = 13601 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.738\n",
      "INFO:tensorflow:loss = 1.60835, step = 13701 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.29\n",
      "INFO:tensorflow:loss = 2.98266, step = 13801 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.932\n",
      "INFO:tensorflow:loss = 3.00002, step = 13901 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.401\n",
      "INFO:tensorflow:loss = 5.85, step = 14001 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.809\n",
      "INFO:tensorflow:loss = 1.2896, step = 14101 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.62\n",
      "INFO:tensorflow:loss = 3.20207, step = 14201 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.494\n",
      "INFO:tensorflow:loss = 3.67522, step = 14301 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.892\n",
      "INFO:tensorflow:loss = 5.74695, step = 14401 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.465\n",
      "INFO:tensorflow:loss = 9.57129, step = 14501 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.129\n",
      "INFO:tensorflow:loss = 5.04177, step = 14601 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.022\n",
      "INFO:tensorflow:loss = 2.69927, step = 14701 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.916\n",
      "INFO:tensorflow:loss = 4.04073, step = 14801 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.076\n",
      "INFO:tensorflow:loss = 2.24891, step = 14901 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.095\n",
      "INFO:tensorflow:loss = 4.8162, step = 15001 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.568\n",
      "INFO:tensorflow:loss = 5.17137, step = 15101 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.11\n",
      "INFO:tensorflow:loss = 7.01928, step = 15201 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.965\n",
      "INFO:tensorflow:loss = 1.2739, step = 15301 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.437\n",
      "INFO:tensorflow:loss = 5.48126, step = 15401 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.98\n",
      "INFO:tensorflow:loss = 3.52089, step = 15501 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.178\n",
      "INFO:tensorflow:loss = 1.42901, step = 15601 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.637\n",
      "INFO:tensorflow:loss = 5.6182, step = 15701 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.548\n",
      "INFO:tensorflow:loss = 2.83735, step = 15801 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.704\n",
      "INFO:tensorflow:loss = 4.90926, step = 15901 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.019\n",
      "INFO:tensorflow:loss = 6.88538, step = 16001 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.188\n",
      "INFO:tensorflow:loss = 2.39794, step = 16101 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.97\n",
      "INFO:tensorflow:loss = 5.15218, step = 16201 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.926\n",
      "INFO:tensorflow:loss = 3.57748, step = 16301 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.051\n",
      "INFO:tensorflow:loss = 0.650296, step = 16401 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.589\n",
      "INFO:tensorflow:loss = 3.77048, step = 16501 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.168\n",
      "INFO:tensorflow:loss = 3.44892, step = 16601 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.964\n",
      "INFO:tensorflow:loss = 3.66, step = 16701 (0.326 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 292.048\n",
      "INFO:tensorflow:loss = 4.06383, step = 16801 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.771\n",
      "INFO:tensorflow:loss = 4.35222, step = 16901 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.625\n",
      "INFO:tensorflow:loss = 9.133, step = 17001 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.41\n",
      "INFO:tensorflow:loss = 2.18911, step = 17101 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.259\n",
      "INFO:tensorflow:loss = 3.25862, step = 17201 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.301\n",
      "INFO:tensorflow:loss = 4.80247, step = 17301 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.824\n",
      "INFO:tensorflow:loss = 4.71873, step = 17401 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.977\n",
      "INFO:tensorflow:loss = 1.12797, step = 17501 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.77\n",
      "INFO:tensorflow:loss = 0.904111, step = 17601 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.699\n",
      "INFO:tensorflow:loss = 6.96764, step = 17701 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.328\n",
      "INFO:tensorflow:loss = 3.41978, step = 17801 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.767\n",
      "INFO:tensorflow:loss = 3.64407, step = 17901 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.674\n",
      "INFO:tensorflow:loss = 3.13626, step = 18001 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.307\n",
      "INFO:tensorflow:loss = 1.41097, step = 18101 (0.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.803\n",
      "INFO:tensorflow:loss = 3.54668, step = 18201 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.028\n",
      "INFO:tensorflow:loss = 1.25893, step = 18301 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.549\n",
      "INFO:tensorflow:loss = 3.35206, step = 18401 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.017\n",
      "INFO:tensorflow:loss = 4.84313, step = 18501 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.113\n",
      "INFO:tensorflow:loss = 4.00082, step = 18601 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.707\n",
      "INFO:tensorflow:loss = 1.78138, step = 18701 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.94\n",
      "INFO:tensorflow:loss = 3.32643, step = 18801 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.25\n",
      "INFO:tensorflow:loss = 5.48845, step = 18901 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.908\n",
      "INFO:tensorflow:loss = 7.18573, step = 19001 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.518\n",
      "INFO:tensorflow:loss = 3.7697, step = 19101 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.586\n",
      "INFO:tensorflow:loss = 1.03743, step = 19201 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.822\n",
      "INFO:tensorflow:loss = 2.96707, step = 19301 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.425\n",
      "INFO:tensorflow:loss = 5.98113, step = 19401 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.194\n",
      "INFO:tensorflow:loss = 0.874064, step = 19501 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.989\n",
      "INFO:tensorflow:loss = 3.14279, step = 19601 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.787\n",
      "INFO:tensorflow:loss = 2.34262, step = 19701 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.692\n",
      "INFO:tensorflow:loss = 1.77426, step = 19801 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.751\n",
      "INFO:tensorflow:loss = 1.23479, step = 19901 (0.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.822\n",
      "INFO:tensorflow:loss = 2.60295, step = 20001 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.201\n",
      "INFO:tensorflow:loss = 2.88127, step = 20101 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.477\n",
      "INFO:tensorflow:loss = 2.71184, step = 20201 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.141\n",
      "INFO:tensorflow:loss = 4.48904, step = 20301 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.742\n",
      "INFO:tensorflow:loss = 5.07144, step = 20401 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.228\n",
      "INFO:tensorflow:loss = 1.85277, step = 20501 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.191\n",
      "INFO:tensorflow:loss = 5.57112, step = 20601 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.237\n",
      "INFO:tensorflow:loss = 3.81083, step = 20701 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.953\n",
      "INFO:tensorflow:loss = 4.93652, step = 20801 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.87\n",
      "INFO:tensorflow:loss = 2.3412, step = 20901 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.991\n",
      "INFO:tensorflow:loss = 5.33908, step = 21001 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.725\n",
      "INFO:tensorflow:loss = 2.03122, step = 21101 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.413\n",
      "INFO:tensorflow:loss = 7.95807, step = 21201 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.021\n",
      "INFO:tensorflow:loss = 4.23301, step = 21301 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.51\n",
      "INFO:tensorflow:loss = 2.47101, step = 21401 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.463\n",
      "INFO:tensorflow:loss = 1.63707, step = 21501 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.438\n",
      "INFO:tensorflow:loss = 4.44853, step = 21601 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.633\n",
      "INFO:tensorflow:loss = 2.25227, step = 21701 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.21\n",
      "INFO:tensorflow:loss = 2.11416, step = 21801 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.643\n",
      "INFO:tensorflow:loss = 3.92986, step = 21901 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.17\n",
      "INFO:tensorflow:loss = 7.76016, step = 22001 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.363\n",
      "INFO:tensorflow:loss = 1.27411, step = 22101 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.118\n",
      "INFO:tensorflow:loss = 3.46276, step = 22201 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.235\n",
      "INFO:tensorflow:loss = 4.10434, step = 22301 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.348\n",
      "INFO:tensorflow:loss = 5.92159, step = 22401 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.202\n",
      "INFO:tensorflow:loss = 1.16657, step = 22501 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.347\n",
      "INFO:tensorflow:loss = 3.56346, step = 22601 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.668\n",
      "INFO:tensorflow:loss = 4.17762, step = 22701 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.657\n",
      "INFO:tensorflow:loss = 2.38727, step = 22801 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.253\n",
      "INFO:tensorflow:loss = 3.76526, step = 22901 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.506\n",
      "INFO:tensorflow:loss = 3.72514, step = 23001 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.153\n",
      "INFO:tensorflow:loss = 2.60092, step = 23101 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.805\n",
      "INFO:tensorflow:loss = 5.83063, step = 23201 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.602\n",
      "INFO:tensorflow:loss = 3.86801, step = 23301 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.756\n",
      "INFO:tensorflow:loss = 2.36952, step = 23401 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.018\n",
      "INFO:tensorflow:loss = 1.51079, step = 23501 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.063\n",
      "INFO:tensorflow:loss = 4.83699, step = 23601 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.063\n",
      "INFO:tensorflow:loss = 1.20207, step = 23701 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.903\n",
      "INFO:tensorflow:loss = 1.09284, step = 23801 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.341\n",
      "INFO:tensorflow:loss = 2.58509, step = 23901 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.494\n",
      "INFO:tensorflow:loss = 4.14442, step = 24001 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.524\n",
      "INFO:tensorflow:loss = 2.03381, step = 24101 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.573\n",
      "INFO:tensorflow:loss = 3.81632, step = 24201 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.293\n",
      "INFO:tensorflow:loss = 5.26355, step = 24301 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.79\n",
      "INFO:tensorflow:loss = 3.47161, step = 24401 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.262\n",
      "INFO:tensorflow:loss = 5.02825, step = 24501 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.29\n",
      "INFO:tensorflow:loss = 3.45084, step = 24601 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.885\n",
      "INFO:tensorflow:loss = 7.65886, step = 24701 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.798\n",
      "INFO:tensorflow:loss = 5.75532, step = 24801 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.401\n",
      "INFO:tensorflow:loss = 3.47128, step = 24901 (0.428 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into C:\\Users\\Surbhi\\AppData\\Local\\Temp\\tmp0stj2tkz\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.87845.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x2aac8a97ba8>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_function,steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function. We only supprt X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input_func = tf.estimator.inputs.pandas_input_fn(X_test,batch_size =10,num_epochs =1,shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Surbhi\\AppData\\Local\\Temp\\tmp0stj2tkz\\model.ckpt-25000\n"
     ]
    }
   ],
   "source": [
    "pred = list(model.predict(test_input_func))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in your list will look like this: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([0], dtype=int64),\n",
       " 'classes': array([b'0'], dtype=object),\n",
       " 'logistic': array([ 0.24739254], dtype=float32),\n",
       " 'logits': array([-1.11256742], dtype=float32),\n",
       " 'probabilities': array([ 0.75260746,  0.24739255], dtype=float32)}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a list of only the class_ids key values from the prediction list of dictionaries, these are the predictions used to compare against the real y_test values. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for each in pred:\n",
    "    prediction.append(each['class_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91      7436\n",
      "          1       0.75      0.59      0.66      2333\n",
      "\n",
      "avg / total       0.85      0.85      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6970  466]\n",
      " [ 965 1368]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "We observe an accuracy of 85% which looks to be good enough. We can perform feature scaling to see further improvements in the performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
